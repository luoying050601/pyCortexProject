{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/home/ying/project/pyCortexProj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba4380851fe4dd992be30defecec89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f008e878c0a04e39a6e953be68f5d102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe67985cd7c4c05b91106027f65da51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 15376/15376 [1:06:24<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:17<00:00, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "Proj_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "print(Proj_dir)\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(Proj_dir)\n",
    "brainlm_word_embedding = {}\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ridgeRegression.brainbert_pretrain_model import BrainBertModel\n",
    "from ridgeRegression.create_word_embedding import get_brain_bert_attention_output\n",
    "from transformers import BertTokenizer\n",
    "import json\n",
    "\n",
    "subj = \"sub_EN057\"\n",
    "proj_dir = \"/home/ying/project/pyCortexProj/\"\n",
    "# import numpy as np\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(proj_dir +\n",
    "                 'ridgeRegression/text_embedding/littlePrince/lppEN_word_embeddings_BERT.csv',\n",
    "                 sep=',', index_col=0, header=0)\n",
    "# df = df['word']\n",
    "# /Storage2/ying/resources/BrainBertTorch/output/ckpt/bert-large-uncased_5_55.56_205410.pt\n",
    "brainBERT_checkpoint = '/Storage2/ying/pyCortexProj/ridgeRegression/models/alice_ae_100.0_286230.pt'\n",
    "checkpoint = {k.replace('module.brainbert.', ''): v for k, v in torch.load(brainBERT_checkpoint).items()}\n",
    "model_config = '/Storage2/ying/pyCortexProj/ridgeRegression/models/brainbert-large.json'\n",
    "model = BrainBertModel.from_pretrained(model_config, checkpoint)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "test_flag = True\n",
    "brainlm = []\n",
    "\n",
    "print(\"loading...\")\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "# for index, row in df.iterrows():\n",
    "    word = row['word']\n",
    "    sequence_output, pooled_output, hidden_states, attentions = get_brain_bert_attention_output(\n",
    "        sentence=word, img_feat=None, tokenizer=tokenizer, model=model)\n",
    "    embedding_list = pooled_output.detach().squeeze(0).tolist()\n",
    "    brainlm.append(pooled_output.reshape(-1).tolist())\n",
    "\n",
    "\n",
    "brainlm_word_embedding[\"brainlm\"] = brainlm\n",
    "\n",
    "print(\"saving...\")\n",
    "for k, v in tqdm(brainlm_word_embedding.items()):\n",
    "    with h5py.File(proj_dir + 'resource/littlePrince/'+subj+'/brainLM286230_word_embedding_whole_words_' + k + '.h5',\n",
    "                   'w') as hf:\n",
    "        # 将数据写入文件，可以是数组、数据集等\n",
    "        hf.create_dataset(subj, data=json.dumps({k: v}))\n",
    "        hf.close()\n",
    "\n",
    "print(\"ending...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
